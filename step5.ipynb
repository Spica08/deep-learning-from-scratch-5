{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPge//J66K4fadZFxQpnmIg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spica08/deep-learning-from-scratch-5/blob/main/step5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAwGoI4ZOn1T"
      },
      "outputs": [],
      "source": [
        "# set up\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step5 EMアルゴリズム"
      ],
      "metadata": {
        "id": "4Q22efOlOveT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 KLダイバージェンス"
      ],
      "metadata": {
        "id": "kTLxabBtO-zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.1 数式の表記について\n",
        "連続型の確率変数xがあり、その確率密度がp(x)で表される時、関数f(x)の期待値は以下のように表す。  \n",
        "\\begin{equation}\n",
        "\\mathbb{E}_{p(x)}[f(x)] = \\int f(x)p(x)dx\n",
        "\\end{equation}\n",
        "また、パラメータθを持つ確率分布は以下のように表す。\n",
        "\\begin{equation}\n",
        "p_\\theta(x)\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "BuEtJiQrPB4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.2 KLダイバージェンスの定義式\n",
        "2つの確率分布を測る尺度の1つであるKLダイバージェンスは以下の式で表される。\n",
        "\\begin{equation}\n",
        "D_{KL}(p||q) = \\int p(x)log\\frac{p(x)}{q(x)}dx ・・・連続変数\n",
        "\\end{equation}\n",
        "\\begin{equation}\n",
        "D_{KL}(p||q) = \\sum\\nolimits_{x} p(x)log\\frac{p(x)}{q(x)}dx ・・・離散変数\n",
        "\\end{equation}\n",
        "KLダイバージェンスは以下の特性を持つ。  \n",
        "(1) 2つの確率分布が異なるほど大きな値をとる。  \n",
        "(2) 0以上の値を取り、2つの確率分布が同じ時のみ0になる。  \n",
        "(3) 非対称な尺度であり、 $D_{KL}(p||q)$と$D_{KL}(q||p)$は異なる値となる。  \n"
      ],
      "metadata": {
        "id": "AXlCaY3eP55E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.3 KLダイバージェンスと最尤推定の関係\n",
        "仮に、真の確率分布$p_*(x)$があり、サンプルデータ$D = \\lbrace x^{(1)}, x^{(2)}, \\dots, x^{(n)}\\rbrace$が得られた場合を考える。この時の目的は、パラメータθで調整できる確率分布$p_\\theta(x)$を使って、真の分布$p_*(x)$にできるだけ近い確率分布を作ることである。最尤推定では、以下の対数尤度を目的関数とする。\n",
        "\\begin{equation}\n",
        "log\\prod_{n = 1}^N p_\\theta(x^{(n)}) = \\sum_{n = 1}^N log p_\\theta(x^{(n)})\n",
        "\\end{equation}\n",
        "この時、対数尤度を最大化するパラメータは以下の通り\n",
        "\\begin{equation}\n",
        "\\hat{\\theta} = argmax_\\theta \\sum_{n = 1}^N log p_\\theta(x^{(n)})\n",
        "\\end{equation}\n",
        "これをKLダイバージェンスから導く。"
      ],
      "metadata": {
        "id": "YloB4V_tQ61X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最終的な目的(=パラメータθで調整できる確率分布$p_\\theta(x)$を使って、真の分布$p_*(x)$にできるだけ近い確率分布を作る)は、「$p_\\theta(x)$と$p_*(x)$のKLダイバージェンスを最小化する」と言い換えられる。2つの分布のKLダイバージェンスは、\n",
        "\\begin{equation}\n",
        "D_{KL}(p_*||p_\\theta) = \\int p_*(x) log \\frac{p_*(x)}{p_\\theta(x)}d\\theta\n",
        "\\end{equation}\n",
        "$p_*(x)$の表現が不明なためこの積分は計算できない。そこでこの計算を**モンテカルロ法**により近似することを考える。  \n"
      ],
      "metadata": {
        "id": "kMcS1z55ShHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.3.1 モンテカルロ法の説明\n",
        "モンテカルロ法は、乱数を用いて複雑な確率分布や期待値などの近似値を計算するための手法。ランダムに生成されたサンプルを用いて問題をシミュレートし、それらのサンプルから求めた結果の平均を取ることで問題の解を近似する。ここではモンテカルロ法を用いて以下の期待値を求める。\n",
        "\\begin{equation}\n",
        "\\mathbb{E}_{p_*(x)}[f(x)] = \\int p_*(x) f(x) dx\n",
        "\\end{equation}\n",
        "ここで、$p_*(x)$は確率分布、$f(x)$は任意の関数である。先ほど同様具体的な真の分布が不明なため積分計算は不可能であるため、モンテカルロ法を用いて以下のように近似する。  \n",
        "(1) 確率分布$p_*(x)$に従ってサンプル{$x^{(1)}, x^{(2)}, ..., x^{(N)}$}を生成する。  \n",
        "(2) 各データ$x^{(i)}$における$f(x^{(i)})$を求め、平均値を計算する。  \n",
        "この手順により、上の式は以下のように表される。\n",
        "\\begin{align}\n",
        "\\mathbb{E}_{p_*(x)}[f(x)] &= \\int p_*(x) f(x) dx\\\\\n",
        "                           &\\approx \\frac{1}{N} \\sum_{n = 1}^N f(x^{(n)})\\qquad(x^{(n)} \\sim p_*(x))\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "EUfZjn-eUK50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "したがってモンテカルロ法を適用して、\n",
        "\\begin{align}\n",
        "D_{KL}(p_*||p_\\theta) &= \\int p_*(x) log \\frac{p_*(x)}{p_\\theta(x)}d\\theta\\\\\n",
        "                       &\\approx \\frac{1}{N} \\sum_{n = 1}^N log\\frac{p_*(x^{(n)})}{p_\\theta(x^{(n)})} \\qquad(x^{(n)} \\sim p_*(x))\\\\\n",
        "                       &= \\frac{1}{N} \\sum_{n = 1}^N \\left(log p_*(x^{(n)}) - log p_\\theta(x^{(n)}) \\right)\n",
        "\\end{align}\n",
        "これを最小化するパラメータθを求めたいので、\n",
        "\\begin{align}\n",
        "argmin_\\theta &\\approx argmin_\\theta \\left(\\frac{1}{N} \\sum_{n = 1}^N \\left(log p_*(x^{(n)}) - log p_\\theta(x^{(n)}) \\right)\\right)\\\\\n",
        "               &= argmin_\\theta \\left(\\frac{1}{N} \\sum_{n = 1}^N - log p_\\theta(x^{(n)}) \\right) \\qquad \\thetaが関与する項のみ残す\\\\\n",
        "               &= argmin_\\theta \\left(-\\sum_{n = 1}^N log p_\\theta(x^{(n)}) \\right)\\\\\n",
        "               &= argmax_\\theta \\left(\\sum_{n = 1}^N log p_\\theta(x^{(n)}) \\right)\n",
        "\\end{align}\n",
        "以上より、\n",
        "\\begin{align}\n",
        "argmin_\\theta D_{KL}(p_*||p_\\theta) &\\approx argmax_\\theta \\left(\\sum_{n = 1}^N log p_\\theta(x^{(n)}) \\right)\n",
        "\\end{align}\n",
        "が成り立ち、KLダイバージェンスが最小となるパラメータθと、対数尤度が最大となるパラメータθが等しいことが示された。"
      ],
      "metadata": {
        "id": "CiGEEK6JWEjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 EMアルゴリズムの導出1"
      ],
      "metadata": {
        "id": "Jg2wFo3tZO1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.1 潜在変数を持つモデル\n",
        "観測できる確率変数をx、潜在変数をz、パラメータをθで表すとき、1つのデータに対する対数尤度は確率の周辺化により以下のように表される。\n",
        "\\begin{equation}\n",
        "log p_\\theta(x) = log \\sum\\nolimits_zp_\\theta(x, z)\n",
        "\\end{equation}\n",
        "(確率変数が離散、スカラと仮定している)  \n",
        "続いてサンプル$D = \\lbrace x^{(1)}, x^{(2)}, \\dots, x^{(n)}\\rbrace$が得られた場合を考える。このサンプルに対する対数尤度は、\n",
        "\\begin{align}\n",
        "log p_\\theta(D) &= log \\left(p_\\theta(x^{(1)})p_\\theta(x^{(2)}) \\dots p_\\theta(x^{(N)})\\right)\\\\\n",
        "                 &= \\sum_{n = 1}^N log p_\\theta(x^{(n)})\\\\\n",
        "                 &= \\sum_{n = 1}^N log \\sum\\nolimits_{z^{(n)}} p_\\theta(x^{(n)}, z^{(n)})\n",
        "\\end{align}\n",
        "これはlog-sumの形となっており解析的に解くことができない。EMアルゴリズムではこれをsum-logの形に変換することで解決する。(潜在変数の確率分布はサンプルごとに仮定している？)  \n",
        "これ以降、まずは1つのデータに関するEMアルゴリズムを考え、その後N個のデータへと拡張する。"
      ],
      "metadata": {
        "id": "rjmqhjVRZcUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1つのデータに関する対数尤度についてもう一度考える。\n",
        "\\begin{align}\n",
        "log p_\\theta(x) &= log \\sum\\nolimits_zp_\\theta(x, z)\\\\\n",
        "                &= log \\frac{p_\\theta(x, z)}{p_\\theta(z | x)} \\qquad 確率の乗法定理より\n",
        "\\end{align}\n",
        "分母の条件付き確率(パラメータθの元でデータxが得られた時の、潜在変数zの事後分布？)の存在によりlog-sumを解決できたわけではない。"
      ],
      "metadata": {
        "id": "9g3qnA4pcF-7"
      }
    }
  ]
}