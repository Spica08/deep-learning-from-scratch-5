{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMProlV4ChMleiUuGozVe/V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spica08/deep-learning-from-scratch-5/blob/main/step9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "255AZIUWD_JJ"
      },
      "outputs": [],
      "source": [
        "# set up\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step9 拡散モデルの実装"
      ],
      "metadata": {
        "id": "7wu8ShAZECjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.1 U-Net\n",
        "8.6.4で見たように、拡散モデルで使用されるニューラルネットワークは、数式では$\\epsilon_\\theta(x_t, t)$と表される。このニューラルネットワークは$x_t$を生成する際に加えられたノイズを予測する。  \n",
        "\n",
        "このニューラルネットワークの入力は$x_t$とtの2つである。まずはtを省略したモデルを作成し、続いて時刻を加えたモデルを実装する。  \n",
        "\n",
        "拡散モデルで用いるモデルは、入力と出力の形状が同じ必要がある。この要件を満たすモデルはAutoEncoderやFCNなどが挙げられ。拡散モデルではU-Netがよく使用される。"
      ],
      "metadata": {
        "id": "poJngbXJEICI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1.1 U-Netとは\n",
        "略"
      ],
      "metadata": {
        "id": "gi9JT74uFYDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1.2 U-Netの実装\n",
        "MNISTデータセットを利用したシンプルなU-Netの実装を行う。  \n",
        "\n",
        "まず、ConvBlock(convolution -> batch normalization -> ReLUを2層)を実装する。"
      ],
      "metadata": {
        "id": "8jw8mIjcFmUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make convolutional block\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "xXRSnqxzGJug"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "続いてUNet"
      ],
      "metadata": {
        "id": "dTG1iXDPLovZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make U-Net\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.down1 = ConvBlock(in_ch, 64)\n",
        "        self.down2 = ConvBlock(64, 128)\n",
        "        self.bot1 = ConvBlock(128, 256)\n",
        "        self.up2 = ConvBlock(128 + 256, 128)\n",
        "        self.up1 = ConvBlock(128 + 64, 64)\n",
        "        self.out = nn.Conv2d(64, in_ch, kernel_size = 3, padding = 1)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2) # strideのデフォルトはkernel_size\n",
        "        self.upsample = nn.Upsample(scale_factor = 2, mode = \"bilinear\")\n",
        "\n",
        "    # x.shape -> (B, 1, 28, 28)\n",
        "    def forward(self, x):\n",
        "        x1 = self.down1(x) # -> (B, 64, 28, 28)\n",
        "        x = self.maxpool(x1) # -> (B, 64, 14, 14)\n",
        "        x2 = self.down2(x) # -> (B, 128, 14, 14)\n",
        "        x = self.maxpool(x2) # -> (B, 128, 7, 7)\n",
        "\n",
        "        x = self.bot1(x) # -> (B, 256, 7, 7)\n",
        "\n",
        "        x = self.upsample(x) # -> (B, 256, 14, 14)\n",
        "        x = torch.cat([x, x2], dim = 1) # -> (B, 128 + 256, 14, 14)\n",
        "        x = self.up2(x) # -> (B, 128, 14, 14)\n",
        "        x = self.upsample(x) # -> (B, 128, 28, 28)\n",
        "        x = torch.cat([x, x1], dim = 1) # -> (B, 128 + 64, 28, 28)\n",
        "        x = self.up1(x) # -> (B, 64, 28, 28)\n",
        "        x = self.out(x) # -> (B, 1, 28, 28)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "luV_CCQHRvFS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check model\n",
        "model = UNet()\n",
        "x = torch.randn(10, 1, 28, 28)\n",
        "y = model(x)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPCiOrUmO08M",
        "outputId": "22878542-6d9e-4d29-e54f-03aa1307eef2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.2 正弦波位置エンコーディング\n",
        "$x_t$を処理するU-Netが実装できたので、時刻tの情報を取り入れるようにすれば良い。拡散モデルではtの情報のエンコーディングにしばしば正弦波エンコーディングが用いられる。"
      ],
      "metadata": {
        "id": "VkB6BE7FPuM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2.1 正弦波位置エンコーディングとは\n",
        "正弦波位置エンコーディングでは、正弦波(サイン波)を使って位置情報をエンコーディングする。  \n",
        "整数tをベクトルvへと変換するとき、変換後のベクトルの次元数をDとするとi番目の要素は以下のように表される。  \n",
        "\\begin{equation}\n",
        "v_i =\n",
        "    \\begin{cases}\n",
        "        sin{\\left(\\frac{t}{10000^{\\frac{i}{D}}}\\right)} & iが偶数\\\\\n",
        "        cos{\\left(\\frac{t}{10000^{\\frac{i}{D}}}\\right)} & iが奇数\n",
        "    \\end{cases}\n",
        "\\end{equation}\n",
        "位置情報を絶対的な値ではなく周期的な特性を持つ三角関数を通じてエンコードする。これにより、位置情報の相対的な差異や周期的なパターンが明確に表現でき、モデルは系列データ中の相対位置の関係性をより効果的に学習できるようになる。"
      ],
      "metadata": {
        "id": "F6Yx3KQdQEdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2.2 正弦波位置エンコーディングの実装"
      ],
      "metadata": {
        "id": "ogjSlB4xRu8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode 1 time point\n",
        "def _pos_encoding(t, output_dim, device = 'cpu'):\n",
        "    D = output_dim\n",
        "    v = torch.zeros(D, device = device)\n",
        "\n",
        "    i = torch.arange(0, D, device = device)\n",
        "    div_term = 10000 ** (i / D)\n",
        "\n",
        "    v[0::2] = torch.sin(t / div_term[0::2])\n",
        "    v[1::2] = torch.cos(t / div_term[1::2])\n",
        "    return v"
      ],
      "metadata": {
        "id": "m63dM7ldR6A7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(_pos_encoding(1, 16))\n",
        "print(_pos_encoding(1, 16).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCxnttM4TDyH",
        "outputId": "f09ab488-454b-4c12-c0ba-28fcd2064022"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8.4147e-01, 8.4601e-01, 3.1098e-01, 9.8423e-01, 9.9833e-02, 9.9842e-01,\n",
            "        3.1618e-02, 9.9984e-01, 9.9998e-03, 9.9998e-01, 3.1623e-03, 1.0000e+00,\n",
            "        1.0000e-03, 1.0000e+00, 3.1623e-04, 1.0000e+00])\n",
            "torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode multiple time point\n",
        "def pos_encoding(ts, output_dim, device = 'cpu'):\n",
        "    batch_size = len(ts)\n",
        "    v = torch.zeros(batch_size, output_dim, device = device)\n",
        "\n",
        "    for i, t in enumerate(ts):\n",
        "        v[i] = _pos_encoding(t, output_dim, device)\n",
        "    return v"
      ],
      "metadata": {
        "id": "pM4z_ThzTaYN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = pos_encoding(torch.tensor([1, 2, 3]), 16)\n",
        "print(v)\n",
        "print(v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVWJVKzPUONI",
        "outputId": "af1f4f7d-b0fd-43f2-8bfd-7315716a29b8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 8.4147e-01,  8.4601e-01,  3.1098e-01,  9.8423e-01,  9.9833e-02,\n",
            "          9.9842e-01,  3.1618e-02,  9.9984e-01,  9.9998e-03,  9.9998e-01,\n",
            "          3.1623e-03,  1.0000e+00,  1.0000e-03,  1.0000e+00,  3.1623e-04,\n",
            "          1.0000e+00],\n",
            "        [ 9.0930e-01,  4.3146e-01,  5.9113e-01,  9.3742e-01,  1.9867e-01,\n",
            "          9.9368e-01,  6.3203e-02,  9.9937e-01,  1.9999e-02,  9.9994e-01,\n",
            "          6.3245e-03,  9.9999e-01,  2.0000e-03,  1.0000e+00,  6.3246e-04,\n",
            "          1.0000e+00],\n",
            "        [ 1.4112e-01, -1.1597e-01,  8.1265e-01,  8.6104e-01,  2.9552e-01,\n",
            "          9.8580e-01,  9.4726e-02,  9.9858e-01,  2.9995e-02,  9.9986e-01,\n",
            "          9.4867e-03,  9.9999e-01,  3.0000e-03,  1.0000e+00,  9.4868e-04,\n",
            "          1.0000e+00]])\n",
            "torch.Size([3, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2.3 U-Netに組み込む"
      ],
      "metadata": {
        "id": "aWHwCovlUb7f"
      }
    }
  ]
}